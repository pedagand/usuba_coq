\documentclass[11pt]{article}
\usepackage[francais]{babel}
\usepackage[utf8]{inputenc}


\usepackage{hyperref}
% \usepackage[ruled, vlined]{algorithm2e}

\usepackage{latexsym,amsmath,xcolor,multicol,booktabs,calligra}
\usepackage{amssymb}
% \usepackage{graphicx,pstricks,listings,stackengine}
\usepackage{listings}
\usepackage{proof}
\usepackage{color}

\usepackage[sorting=none]{biblatex}
\addbibresource{main.bib}

\usepackage[margin=2.5cm]{geometry}

\newcommand{\Usuba}{\textsc{Usuba}}
\newcommand{\UsubaA}{$\textsc{Usuba}_1$}
\newcommand{\UsubaB}{$\textsc{Usuba}_2$}
\newcommand{\doubleplus}{+\!\!\!+\;}

\title{\Usuba}
\author{Samuel \textsc{Vivien}}
\date{Spring 2023}

\include{rules}


\newcommand{\ottdruleBinopBis}[1]{\ottdrule[#1]{%
\ottpremise{\Gamma  \ottsym{,}  \ottnt{P}  \ottsym{,}  \ottnt{A}  \vdash_E  \ottnt{e_{{\mathrm{1}}}}  \ottsym{:}  \tau_1}%
\ottpremise{\Gamma  \ottsym{,}  \ottnt{P}  \ottsym{,}  \ottnt{A}  \vdash_E  \ottnt{e_{{\mathrm{2}}}}  \ottsym{:}  \tau_2}%
\ottpremise{\ottnt{A}  \vdash  \ottkw{ClassOf} \,  \ottnt{binop}  \, (\tau_1 \land \tau_2)}%
}{
\Gamma  \ottsym{,}  \ottnt{P}  \ottsym{,}  \ottnt{A}  \vdash_E   %(
  \ottnt{e_{{\mathrm{1}}}} %\, \ottkw{into} \, \tau_1 \land \tau_2)\; 
  \ottnt{binop} _{ \tau_1 \land \tau_2 } \;  %(
    \ottnt{e_{{\mathrm{2}}}}% \, \ottkw{into} \, \tau_1 \land \tau_2)
    \ottsym{:}  \tau_1 \land \tau_2}{%
{\ottdrulename{Binop}}{}%
}}


\renewcommand{\ottdruleFun}[1]{\ottdrule[#1]{%
\ottpremise{\ottnt{P}  \vdash  \ottmv{f}  \ottsym{:} \, \forall \, \ottcomp{\ottmv{d_{\ottmv{n}}}}{\ottmv{n}} \, \ottsym{,} \, \forall \, \ottcomp{\ottmv{s_{\ottmv{m}}}}{\ottmv{m}} \, \ottsym{,}  \ottcomp{\ottnt{typc_{\ottmv{j}}}}{\ottmv{j}}  \Rightarrow  \mathcal{T}_{{\mathrm{1}}}  \rightarrow  \mathcal{T}_{{\mathrm{2}}}}%
\ottpremise{\Gamma  \ottsym{,}  \ottnt{P}  \ottsym{,}  \ottnt{A}  \vdash_E  \ottsym{(} \, \ottcomp{\ottnt{e_{\ottmv{n}}}}{\ottmv{n}} \, \ottsym{)}  \ottsym{:}  \mathcal{T}'_{{\mathrm{1}}}}%
\ottpremise{\ottnt{A}  \vdash \, \ottcomp{\ottnt{typc_{\ottmv{j}}}  \ottsym{[} \, \ottcomp{\ottmv{d_{\ottmv{n}}}  \leftarrow  \ottmv{d'_{\ottmv{n}}}}{\ottmv{n}} \, \; ; \; \, \ottcomp{\ottmv{s_{\ottmv{m}}}  \leftarrow  \ottmv{s'_{\ottmv{m}}}}{\ottmv{m}} \, \ottsym{]}}{\ottmv{j}}}%
\ottpremise{\mathcal{T}_{{\mathrm{1}}}  \ottsym{[} \, \ottcomp{\ottmv{d_{\ottmv{n}}}  \leftarrow  \ottmv{d'_{\ottmv{n}}}}{\ottmv{n}} \, \; ; \; \, \ottcomp{\ottmv{s_{\ottmv{m}}}  \leftarrow  \ottmv{s'_{\ottmv{m}}}}{\ottmv{m}} \, \ottsym{]}  \ottsym{=}  \ottcomp{\sigma_{\ottmv{x}} \, \ottcomp{\ottsym{[}  \ell_{\ottmv{g}}  \ottsym{]}}{\ottmv{g}} \, \ottcomp{\ottsym{[}  \ottmv{z_{\ottmv{x}, \ottmv{q}}}  \ottsym{]}}{\ottmv{q}}}{\ottmv{x}}}%
\ottpremise{\mathcal{T}_{{\mathrm{2}}}  \ottsym{[} \, \ottcomp{\ottmv{d_{\ottmv{n}}}  \leftarrow  \ottmv{d'_{\ottmv{n}}}}{\ottmv{n}} \, \; ; \; \, \ottcomp{\ottmv{s_{\ottmv{m}}}  \leftarrow  \ottmv{s'_{\ottmv{m}}}}{\ottmv{m}} \, \ottsym{]}  \ottsym{=}  \ottcomp{\sigma'_{\ottmv{y}} \, \ottcomp{\ottsym{[}  \ell_{\ottmv{g}}  \ottsym{]}}{\ottmv{g}} \, \ottcomp{\ottsym{[}  \ottmv{z'_{\ottmv{y}, \ottmv{r}}}  \ottsym{]}}{\ottmv{r}}}{\ottmv{y}}}%
\ottpremise{\mathcal{T}'_{{\mathrm{1}}} \, \cong \, \ottcomp{\sigma_{\ottmv{x}} \, \ottcomp{\ottsym{[}  \ell_{\ottmv{g}}  \ottsym{]}}{\ottmv{g}} \, \ottcomp{\ottsym{[}  \ell'_{\ottmv{h}}  \ottsym{]}}{\ottmv{h}} \, \ottcomp{\ottsym{[}  \ottmv{z_{\ottmv{x}, \ottmv{q}}}  \ottsym{]}}{\ottmv{q}}}{\ottmv{x}}}%
}{
\Gamma  \ottsym{,}  \ottnt{P}  \ottsym{,}  \ottnt{A}  \vdash_E  \ottsym{[} \, \ottcomp{\ell_{\ottmv{g}}}{\ottmv{g}} \, \ottsym{]}  \ottmv{f}  \ottsym{[} \, \ottcomp{\ell'_{\ottmv{h}}}{\ottmv{h}} \, \ottsym{]}  \ottsym{(} \, \ottcomp{\ottnt{e_{\ottmv{n}}}}{\ottmv{n}} \, \ottsym{)}  \ottsym{:}  \ottcomp{\sigma'_{\ottmv{y}} \, \ottcomp{\ottsym{[}  \ell_{\ottmv{g}}  \ottsym{]}}{\ottmv{g}} \, \ottcomp{\ottsym{[}  \ell'_{\ottmv{h}}  \ottsym{]}}{\ottmv{h}} \, \ottcomp{\ottsym{[}  \ottmv{z'_{\ottmv{y}, \ottmv{r}}}  \ottsym{]}}{\ottmv{r}}}{\ottmv{y}}}{%
{\ottdrulename{Fun}}{}%
}}

\begin{document}

\title{\Usuba{}, vers une formalisation du langage}

\author{Samuel \textsc{Vivien}, sous l'encadrement de Pierre-Évariste \textsc{Dagand} -- IRIF}

\date{La date}

\maketitle

\pagestyle{empty} %
\thispagestyle{empty}

%% Attention: pas plus d'un recto-verso!
% Ne conservez pas les questions


\subsection*{Le contexte général}

\UsubaA{} \cite{usuba} est un langage de haut niveau développé pour écrire des primitives cryptographiques
qui cumulent à la fois un haut débit et un temps de calcul indépendant des valeurs.

% De quoi s'agit-il ? 
% D'où vient-il ? 
% Quels sont les travaux déjà accomplis dans ce domaine dans le monde ?

La nécessité de la première propriété est évidente et la particularité d'\UsubaA{} réside dans son implémentation. L'idée est
d'exploiter au maximum les unités de calcul vectoriel des processeurs afin d'augmenter la quantité de calculs effectués en
parallèles. Pour cela différents types d'unités de calcul vectoriel sont utilisées :
\begin{itemize}
\item Les unités AVX afin de faire des opérations arithmétiques entre des entiers 16, 32 ou 64 bits en parallèle
\item Les registres usuels qui permettent de faire des opérations logiques entre 32 ou 64 bits en parallèle sur des architectures arm ou intelx64
\end{itemize}

La seconde propriété est recherchée par les développeurs de primitives cryptographiques car cela permet de diminuer le risque
de fuite de données lié aux attaques par canaux cachés. En effet, si le temps d'exécution d'un code dépend de la clé secrète il
est possible d'obtenir des informations sur la dite clé à partir du temps d'exécution.
Dans un code assembleur, les deux principaux facteurs qui font varier le temps d'exécution en fonction des valeurs sont les saut conditionnels
et les accès mémoires.

Afin d'éviter les saut conditionnels dans le code généré, la solution la plus simple est de les interdire dans le code initial.
\UsubaA{} n'est donc pas un langage Turing-complet car il n'est pas possible d'écrire des conditionnels (\texttt{if}) ou des boucles dynamiques (\texttt{while}).

Le problème des accès mémoire est un problème très étudié et dont il existe des solutions.
Pour résoudre ce problème, il existe en \UsubaA{} deux types de tableaux.
\begin{itemize}
\item Il y a les tableaux statique dont le contenu est connu à la compilation : il s'agit des S-Boxes, utilisées dans les primitives cryptographique.
Il est possible d'accéder au contenu de ces tableaux avec une valeur arbitraire car sinon on ne pourrait écrire que des constantes.
Pour éviter que les accès dans ces tableaux soient des accès mémoire, ils sont remplacé à la compilation par un calcul arithmétique.
Il existe de nombreuses recherches \cite{peralta} sur comment trouver les codes les plus efficace possible pour retirer ces accès mémoire.
\item Il y a aussi les tableaux dynamique dont le contenu n'est connu qu'à l'exécution.
Pour ces tableaux, les seuls accès possible sont par des indices connu à la compilation.
On peux donc remplacer ces tableaux par une liste de variables ce qui évite les accès mémoire.
\end{itemize}

\subsection*{Le problème étudié}

% Quelle est la question que vous avez abordée ? 
% Pourquoi est-elle importante, à quoi cela sert-il d'y répondre ?  
% Est-ce un nouveau problème ?
% Si oui, pourquoi êtes-vous le premier chercheur de l'univers à l'avoir posée ?
% Si non, pourquoi pensiez-vous pouvoir apporter une contribution originale ?

Ce langage possède déjà un compilateur (nommé \textit{usubac}), cependant celui ci possède plusieurs défauts :
\begin{itemize}
\item la correction du dit compilateur n'est pas formellement prouvée, contrairement à CakeML \cite{CakeML} ou CompCert \cite{CompCert},
\item le compilateur n'inclut pas de typeur, seulement des tentative de vérification au court des différentes passes, et
\item il n'existe pas de spécification de la sémantique d'\UsubaA{}.
\end{itemize}

Lorsque quelqu'un écrit un code, la dite personne espère comprendre ce que fait le code qui est écrit.
À moins de lire le code généré, ceci nécessite de faire confiance au compilateur et de comprendre avec exactitude le code initial.
Cependant un compilateur est un mécanisme complexe composé de multiples étapes de réécritures ce qui le rend difficilement compréhensible.
Il devient donc quasiment impossible de savoir ce que fait exactement le compilateur afin d'avoir confiance dans le compilateur.
Un compilateur certifié par assistant de preuve permet de remplir ces deux conditions en fournissant une spécification de la sémantique
ainsi qu'une preuve vérifiable mécaniquement de la préservation de la sémantique.

\subsection*{La contribution proposée}

% Qu'avez vous proposé comme solution à cette question ? 
% Attention, pas de technique, seulement les grandes idées ! 
% Soignez particulièrement la description de la démarche \emph{scientifique}.

Afin de commencer à palier à ces problèmes, ce rapport présentera une variante de \UsubaA{} nommé \UsubaB{},
munie d'une proposition de système de type,
ainsi que 4 spécifications différentes d'une sémantique de \UsubaB{} implémenté en Coq à l'aide de différentes méthodes.
Cependant lors de ce travail des difficultés ont été rencontrées en raison de constructions en \UsubaA{} qui se typent mal.
Pour cela, nous présenterons aussi de nouvelles constructions afin d'améliorer \Usuba{}.

Plusieurs spécification différentes de sémantique pour \UsubaB{} sont proposées afin de pouvoir à la fois clarifier certains
comportement du compilateur actuel, mais aussi d'expérimenter sur différents comportement possible de certaines constructions
afin de voir comment rapprocher ce langage d'un modèle plus équationel.
Les spécificités et avantages des différentes sémantiques seront notamment discutés.

\subsection*{Les arguments en faveur de sa validité}

% Qu'est-ce qui montre que cette solution est une bonne solution ?
% Des expériences, des corollaires ? 
% Commentez la \emph{robustesse} de votre proposition : 
% comment la validité de la solution dépend-elle des hypothèses de travail ?

Afin de tester la validité des sémantiques implémentés, les trois qui calculent ont été extraites de Coq vers du code OCaml afin de
tester le comportement de deux primitives cryptographiques implémentées en \UsubaB{}: ACE et AES.

Afin de tester la validité du comportement de ces deux primitives pour une sémantique donnée, la primitives est 
simulée sur un vecteur test fourni dans la spécification de la primitive afin de vérifier que le résultat est bien celui attendu.

\subsection*{Le bilan et les perspectives}

% Et après ? En quoi votre approche est-elle générale ? 
% Qu'est-ce que votre contribution a apporté au domaine ? 
% Que faudrait-il faire maintenant ? 
% Quelle est la bonne \emph{prochaine} question ?

La contribution finale est loin de l'objectif initial d'implémenter un compilateur certifié.
Cependant ce travail a permis d'exhiber des difficultés dans le comportement existant des codes \Usuba{} ce qui permet d'ouvrir des pistes de réflexion
sur les évolutions possibles du langage.
De plus les différentes implémentations de sémantiques et les discussions associées permettrons d'avoir un recul sur quelle implémentation choisir pour une
implémentation d'un compilateur certifié. De plus cet effort de développement a permis de mettre en place des outils qui permettront de faciliter
une telle implémentation.

\newpage

\section{Syntaxe et comportement de \UsubaA{}}
\label{sec:syntax}

Au court des différentes sections de ce rapport on se basera sur un même code afin d'expliquer les différentes notions mises en jeu.
Il s'agira de l'implémentation en \UsubaA{} de l'algorithme de chiffrement nommé Rectangle \cite{rectangle}.
On défini dans le bloc de code suivant \ref{lst:rectangle} le nœud \texttt{Rectangle}
qui correspond à l'algorithme de chiffrement et le nœud \texttt{MapRectangle} qui applique
l'algorithme point à point sur des listes de 64 éléments.

% Specification: https://eprint.iacr.org/2014/084.pdf
\begin{lstlisting}[caption=Rectangle appliqué à une liste, label=lst:rectangle]
table SubColumn (input:v4) returns (out:v4) {
    6, 5, 12, 10, 1, 14, 7, 9, 11, 0, 3, 13, 8, 15, 4, 2
}

node ShiftRows (input:u16[4]) returns (out:u16[4])
vars
let
    out[0] = input[0];
    out[1] = input[1] <<< 1;
    out[2] = input[2] <<< 12;
    out[3] = input[3] <<< 13
tel

node Rectangle (plain:u16[4],key:const u16[26][4]) returns (cipher:u16[4])
vars
    tmp : u16[26][4]
let

    tmp[0] = plain;
    forall i in [0,24] {
      tmp[i+1] = ShiftRows( SubColumn( tmp[i] ^ key[i] ) )
    }

    cipher = tmp[25] ^ key[25]
tel

node MapRectangle(plain:u16[64][4], key:const u16[64][26][4])
  returns (cipher:u16[64][4])
vars
let
  forall i in [0, 64] {
    cipher[i] = Rectangle(plain[i], key[i])
  }
tel
\end{lstlisting}

Comme on peut le voir dans l'exemple, un programme \UsubaA{} est composé de plusieurs nœuds.
Il en existe deux types : les nœuds d'équations (\texttt{ShiftRows, Rectangle} et \texttt{MapRectangle}) et les tableaux (\texttt{SubColumn})
comme indiqué dans la figure \ref{fig:syntax}.
Ces nœuds correspondent à des fonctions du premier ordre. Les nœuds peuvent en appeler un autre, mais seulement un de ceux qui ont étés définis avant et les
appels récursifs ne sont pas autorisés.
Les récursions ne sont pas autorisées car le langage ne contient pas de conditionnelles.
En effet, si l'on pouvait faire des appels récursif alors on aurait systématiquement une boucle infinie.

Les tableaux permettent d'implémenter des S-BOX.
Les nœuds reçoivent un tableaux de $n$ entiers de $b$ bits qui peuvent être intéprété comme une matrice de $n \times b$ bits.
Puis on interprète chacunes des $b$ colonnes comme un entier de $n$ bits qui est utilisé 
pour faire un accès dans le tableau fournis.
On obtient donc une matrice de $n' \times b$ bits ce qui correspond à $n'$ entiers de $b$ bits.

Les nœuds d'équations sont composés d'une liste de déclarations. Ces déclarations expliquent comment calculer la valeur des variables
renvoyées à partir des variables fournis en entrée.
Dans l'exemple de Rectangle, le nœud \texttt{ShiftRows} est composé de 4 déclarations qui permettent de calculer \texttt{out} à partir de \texttt{input}.
Au total, il existe trois types de déclarations possibles :
\begin{itemize}
\item Les boucles \texttt{for} dont les deux bornes sont connues à la compilation et qui sont composées d'une liste d'équations.
Il s'agit de sucre syntaxique afin d'écrire de façon concise un grand nombre d'équations.
\item Les équations de définition ( $[[ </ vn // n /> <|- e ]]$ ) qui définissent les variables à partir de la valeur calculé par l'expression $[[ e ]]$.
\item Les équations de modification ( $[[ </ vn // n /> <:- e ]]$ ) qui modifient les valeurs des variables dans l'environnement.
Cette construction n'est pas compatible avec une vision équationnelle d'un nœud en raison de sa nature impérative. Elle n'est donc pas supporté dans la plupart
des sémantiques en raison de son incompatibilité avec d'autres fonctionnalités. Ceci n'est pas un problème car cette construction
est vouée à disparaître.
\end{itemize}

Parmi les 4 sémantiques présentées dans la section \ref{sec:sem}, 2 ne sont définies que pour une liste d'équations.
Leur définition commence donc par réécrire le système de déclarations en une liste d'équations en retirant le sucre syntaxique des boucles \texttt{for}.
Cependant cette méthodologie est peu satisfaisante et peut être résolu avec la proposition de la section \ref{sec:wrap}.

\begin{figure}[t]
    \begin{minipage}{0.20\textwidth}
      \ottgrammartabular{
        \ottinterrule
        \ottind\ottinterrule
        \ottv\ottinterrule
        \otta\ottinterrule}
    \end{minipage}
    \begin{minipage}{0.25\textwidth}
        \ottgrammartabular{
          \ottaop\ottinterrule
          \otte
        }
    \end{minipage}
    \begin{minipage}{0.40\textwidth}
        \ottmetavars\\[0pt]
        \ottgrammartabular{
          \ottinterrule
          \ottdeq\ottinterrule
          \ottnodeDef\ottinterrule
          }
    \end{minipage}
    \caption{AST de Usuba}
    \label{fig:syntax}
\end{figure}

Les différents constructeurs d'expressions correspondent à ce que l'on peut trouver usuellement dans un langage de programmation : appel de nœuds,
opérateurs binaire et unaire, tuples, constantes et variables.
La syntaxe pour les appels de nœuds est plus compliquée qu'usuellement.
Un tel appel dépend de deux listes d'entiers qui permettent
d'expliquer au compilateur comment appliquer le nœud sur des tableaux.
La liste de droite permet d'expliquer le nombre de fois qu'il faut appliquer le nœud.
Cela correspond donc à une séquence de \textit{map}.
Par exemple pour l'exemple \ref{lst:rectangle} le nœud \texttt{MapRectangle} fait 64 appels de
nœud simple (i.e. les deux listes sont vides).
Mais on peut écrire une nouvelle version en utilisant cette syntaxe pour obtenir l'exemple \ref{lst:map-rec}.

\begin{lstlisting}[caption=Rectangle appliqué à une liste, label=lst:map-rec]
node MapRectangle(plain:u16[64][4], key:const u16[64][26][4])
  returns (cipher:u16[64][4])
vars
let
  cipher = Rectangle[64](plain, key)
tel
\end{lstlisting}

La liste de gauche explique comment modifier l'ordre des dimensions des tableaux afin que le l'itération du \textit{map} ne soit pas forcément
appliqué sur les dimensions extérieures.
L'idée étant de pouvoir appliquer un \textit{map} mais en itérant sur d'autres dimensions que celles extérieures. Par exemple si l'on veux
appliquer un nœud sur toutes les lignes ou toutes les colonnes d'une matrice.
Cette syntaxe avec les listes d'un appel de nœud est une nouveauté pour le langage \UsubaB{} qui n'est pas implémenté dans \textit{usubac} et qui a pour
but de diminuer le nombres de boucles \texttt{for} qui doivent être écrites.

Plus d'explications sur ces listes sont fournies avec les règles de typages dans la section \ref{sec:typ}.

Les constructeurs de variables sont défini récursivement comme un identifiant ou un indiçage sur une variable.
Un indiçage peut être :
\begin{itemize}
\item Un indice $i$ qui permet de projeter un tableau sur l'un de ses éléments
\item Une liste d'entiers qui permet de générer un nouveau tableau en modifiant une dimension
\item Un intervalle qui est juste du sucre syntaxique pour la liste de tous les entiers dans l'intervalle
\end{itemize}

Par exemple si l'on a un identifiant $x$ qui contient un tableau de 3 entiers 32 bits $[0, 1, 2]$.
Alors la construction $x [2, 0]$ s'évalue en un tableau de 2 entiers $[2, 0]$.

L'implémentation actuelle de usubac fournis une sémantique qui n'est pas compositionnelle.
En effet, si on prend désormais un identifiant $x$ qui contient un tableau de 2 tableaux de 2 entiers $[ [ 0 , 1 ], [2, 3] ]$.
Alors, dans l'implémentation actuelle de \textit{usubac}, la construction $x [0, 1] [ 0 ]$ est du sucre syntaxique pour $(x[0][0], x[1][0])$
qui s'évalue en $[0, 2]$.
Cependant si l'on modifie le contexte avec l'équation $y = x[0, 1]$, alors $y[0]$ s'évalue en $[0, 1]$.

La solution que nous proposons pour résoudre ce problème est de remplacer les indiçage par une séquence d'indiçages car cela permet d'écrire $x[0, 1: 0]$
pour parler de $(x[0][0], x[1][0])$, et garder $x[0, 1][0]$ pour désigner $x[0]$.
Cette nouvelle syntaxe fait perdre la rétro-compatibilité avec les précédents codes \UsubaA{}, cependant cela permet d'avoir une sémantique compositionnelle.

\section{Règles de typage}
\label{sec:typ}

Lors de la section précédente nous avons présenté la syntaxe de \UsubaB{}.
Cependant ce langage ne possède pas de système de type. Il est donc difficile de savoir quels programmes vont être regetés
par le compilateur. Ceci est notamment une conséquence des coercions implicites qui sont très présentes en \UsubaA{}.

Pour cela nous définissions les types $\tau$ comme une tableau multi-dimensionnels contenant un type atomique $\sigma$.
On parle de type atomique car il s'agit de la construction de base pour parler de tous les types des valeurs.
Un tel type $\sigma$ correspond à un entier muni d'une certaine taille $size$ et d'une orientation $dir$ comme indiqué dans la figure \ref{fig:typ-grammar}.
Par exemple, $\textbf{U V}\;32$ correspond à un entier de 32 bits stocké verticalement et
$\textbf{U H}\;64$ correspond à un entier de 64 bits stocké horizontalement.
Un entier vertical correspond à le représentation usuel d'un entier et un entier horizontal
de $b$ bits est lui stocké dans $b$ registres différents.

Cependant la taille et l'orientation sont potentiellement non spécifié afin de permettre du polymorphisme.
Par exemple le type $u32$ dans l'exemple \ref{lst:rectangle} correspond au type atomique $\textbf{U}\;dir\;32$ où $dir$ est une variable de direction.
À partir de ces types atomiques ont peut construire des tableaux pour ainsi obtenir des types tels que
$\textbf{U H}\;32[4]$ ou le type $v4$ qui correspond à $\textbf{U}\;dir\;size[4]$.
L'idée étant que par défaut pour un nœuds, à chaque fois qu'une direction (resp. taille) n'est pas spécifié cela correspond à un même paramètre qui sera
spécifié au niveau de l'appel du nœud.

Cependant les opérations de calcul ne sont pas définies sur tous les entiers.
Par exemple, les opérations arithmétiques sont définies sur les entiers 32 ou 64 bits mais pas sur les entiers 38 bits.
Pour pouvoir garantir au typage que toutes les opérations utilisées sont bien définies, le langage \UsubaB{} contient des classes de types ($typc$ dans la figure \ref{fig:typ-grammar})
qui permettent de spécifier sur quels types sont définies les opérations logiques, arithmétiques et de décalage.
Certaines classes de types peuvent être définies sur un tableau à l'aide du foncteur de liste et si la classes est bien définie sur le type des
éléments du tableau comme indiqué dans la figure \ref{fig:typclass}.
Cependant afin de savoir exactement quelles classes de types sont définies, il faut spécifier à la compilation vers quelle architecture
doit être compilé le code.

À partir des types $\tau$, on défini $\mathcal{T}$ comme une liste de types $\tau$ afin de pouvoir représenter le type d'une expression.

\begin{figure}[t]
    \begin{minipage}{0.20\textwidth}
      \ottgrammartabular{
        \ottdir\ottinterrule
          \ottsize
      }
    \end{minipage}
    \begin{minipage}{0.20\textwidth}
    \ottgrammartabular{
      \otttypi\ottinterrule
      \otttyp\ottinterrule
      \otttypL}
    \end{minipage}
    \begin{minipage}{0.20\textwidth}
      \ottgrammartabular{
        \otttypc\ottinterrule
        \ottA
      }
    \end{minipage}
    \begin{minipage}{0.20\textwidth}
    \ottgrammartabular{
      \ottP\ottinterrule
      \ottG
    }
    \end{minipage}
    \caption{Types et contextes en \UsubaB{}}
    \label{fig:typ-grammar}
\end{figure}

\begin{figure}[t]
  \ottdefnTClass{}
  \caption{Inférence des classes de types}
  \label{fig:typclass}
\end{figure}

À partir de cette syntaxe des types, on peut désormais définir les règles de typage des variables.
Pour cela on définit d'abord dans la figure \ref{fig:typ-ind} comment une liste d'indiçages modifie les dimension d'un tableau puis en
appliquant récursivement ces règles ont obtien les règles de typage des variables présenté dans la figure \ref{fig:typ-var}.

\begin{figure}[t]
  \ottdefnIndexJudge{}
  \caption{Typage des indiçages}
  \label{fig:typ-ind}
\end{figure}

\begin{figure}[t]
  \ottdefnVarJudge{}
  \caption{Typage des variables}
  \label{fig:typ-var}
\end{figure}

À partir du typage des variables, on peut construire les règles de typage des expressions présenté dans la figure \ref{fig:typ-expr}.
Une particularité notable de ces règles de typage est que le type d'une expression est représenté comme une liste de types $\tau$, mais que
deux règles (\textsc{Monop} et \textsc{Binop}) ne sont définies que sur un tableau et non pas une liste de tableaux.

\begin{figure}[h]
  \ottdefnExpType{}
  \caption{Typage des expressions}
  \label{fig:typ-expr}
\end{figure}

La règle la plus compliquée parmi les différentes expressions est la règle de typage d'un appel de nœud.
En effet, lors d'un appel de nœuds il se passe deux choses :
\begin{itemize}
\item Premièrement, le nœud peut être appelé plusieurs fois sur différents morceaux du tableau.
L'idée est que chaque argument est un tableau dont on extrait $\textbf{prod}\; [\overline{\ell'_h}]$ \footnote{Notation pour parler du produit des éléments d'une liste.}
sous tableaux et que le nœud est appelé sur chaque série de tableaux.
Cependant les dimensions sur lesquels on itère pour générer les sous tableaux ne correspondent pas forcément aux dimensions
extérieures car cela permet de pouvoir appliquer un nœud aux colonnes ou aux lignes d'une matrice suivant le besoin.
\item La seconde difficulté au moment de l'appel de nœud est la coercion des arguments vers le type voulu par la fonction.
Il s'agit d'une fonctionnalités très utilisées en \UsubaA{} car elle permet notamment de changer un tableau de 64 éléments en deux tableaux de 32.
Une coercion entre deux types n'est possible que si les deux types sont équivalent pour la notion d'équivalence présentée dans la figure \ref{fig:typ-rel}.
\end{itemize}

\begin{figure}[t]
  \ottdefnTypeComp{}
  \caption{Équivalence de types}
  \label{fig:typ-rel}
\end{figure}

Ces règles peuvent sembler obscures cependant l'intuition derrière est relativement simple et peut être résumé en seulement deux règles :
\begin{itemize}
\item Les entiers 1 bit sont les mêmes pour toute représentation mémoire (verticale ou horizontale). Il s'agit de la règle \textsc{Bool}.
\item Deux listes de types sont identiques si elle contiennent le même nombre d'entiers de chaque taille et orientation dans le même ordre.
\end{itemize}

Cependant ces règles de typage font perdre de l'expressivité à \Usuba{} car elles ne permettent pas de typer certaines opérations
actuellement utilisées dans des codes \UsubaA{}.
Par exemple si l'on a $x$ de type $\textbf{U V}\; 32[2]$ alors $x + (x[0], x[1])$ n'est pas typable.

Pour palier à ce problème nous introduisons dans le langage \UsubaB{} deux nouvelles constructions : les constructeurs de tableaux et les coercions explicites.
Les constructeurs de tableaux ont pour but de pouvoir permettre de gérer 
d'écrires des multiplets qui ont pour type une liste de $\tau$.
Cependant cela ne permet toujours pas à gérer tous les cas. C'est pour ça que l'on introduit les coercions explicites.
Cela nous donne deux nouvelles règles de typage présentées dans la figure \ref{fig:typ-exprbis}.

\begin{figure}[h]
  \ottdefnExpTypeBis{}
  \caption{Typage des expressions, partie 2}
  \label{fig:typ-exprbis}
\end{figure}

Une fois que l'on sait comment typer les expressions on peut désormais vérifier que les déclarations sont bien typées.
Pour cela on vérifie que les équations préservent bien le type et que les boucles contiennent que des sous déclarations cohérentes comme
indiqué dans la figure \ref{fig:typ-deq}.

\begin{figure}[h]
  \ottdefnTypeDeq{}
  \caption{Typage des équations}
  \label{fig:typ-deq}
\end{figure}

Le typage des nœuds contient deux règles présentées dans la figure \ref{fig:typ-node}. La règle de typage des nœuds d'équations indique que toutes les équations
doivent être bien typées dans le contexte de toutes les variables.

Le typage d'une table est plus subtil car il reflète la sémantique d'une table présenté dans la section \ref{sec:syntax}.
Une table prend en entrée $i_1$ entiers de $s$ bits pour obtenir $s$ entiers de $i_1$ bits.
Ces entiers permettent de faire $s$ accès dans la table qui contient $1 \ll i_1$ entiers de $i_2$ bits.
On obtient alors $s$ entiers de $i_2$ bits qui transformé en $i_2$ entiers de $s$ bits.
De plus la raison pour laquelle on demande à ce que les opérations logiques soient définie sur les entiers est pour pouvoir remplacer ce nœud par une liste
d'équation afin d'éviter les accès mémoires.

\begin{figure}[h]
  \ottdefnTypeNode{}
  \caption{Typage d'un nœud}
  \label{fig:typ-node}
\end{figure}



\section{Sémantiques}
\label{sec:sem}

Afin de fournir une spécification du langage \UsubaB{} dans le but d'implémenter un compilateur certifié par assistant de preuve
il faut implémenter la sémantique voulu dans un assistant de preuve.
L'assistant de preuve choisi pour cette formalisation est Coq en raison de sa compatibilité avec \textsc{OCaml} car \textit{usubac} est écrit dans ce langage.

Au total quatres sémantiques différentes ont été implémentées. Parmi celles-ci, trois d'entre elles calculent un résultat et la quatrième est
une relation qui vit dans \texttt{Prop}.

Les différences entre ces sémantiques se situent au niveau de leur définition et de leur gestion du contexte. 
Les discussions dans les paragraphes qui suivent se concentrerons sur ces différences mais nous présenterons tout d'abord leurs points communs.

\subsection{Points communs des sémantiques}

Tout d'abord toutes les sémantiques ont une même notion de valeur qui est un type somme entre un entier (pour les valeurs statiques)
et un tableau multidimensionnel qui est défini comme un triplet direction, entiers stockés dans la tableau et liste des dimensions.
Ces valeurs correspondent à un élément de type $\tau$. Une liste de telles valeurs correspond à un élément de type $\mathcal{T}$.
De plus pour les 3 sémantiques qui calculent, les erreurs sont représentées par un type option où \texttt{None} correspond à une erreur.

Le second point commun entre ces 3 sémantiques qui calculent est la gestion de la sémantique des nœuds.
En effet, la sémantique d'un nœud est défini comme une fonction d'une liste de valeurs dans une option de liste de valeurs.
On peut alors passer à la fonction d'évaluation du corps d'un nœud une liste de la sémantique de tous les nœuds défini précédemment
sans créer de récursivité mutuelle entre les différentes fonctions de définition de la sémantique.

\subsection{Sémantique par évaluation}
\label{sec:evalsem}

La première sémantique implémentée pour \UsubaB{} est une sémantique par évaluatation.
Cette sémantique est définie de façon intuitive: on évalue toutes les équations dans l'ordre du programme.
En effet, la sémantique d'une expression est définie à partir d'une fonction qui pour toute
expression prend un contexte et renvoie une option de liste de valeurs.
Pour cette sémantique, un contexte est définie pour une structure (en l'occurrence une liste de paire) qui associe à certains identifiants une
valeur incomplète. Une valeur incomplète est une valeur où l'on a remplacé la liste des éléments d'un tableau par une liste d'option pour pouvoir
désigner les éléments pas encore défini.

Par exemple dans le système $\{v[0] = 1; v[1] = v[0] \}$ avec $v$ de type $\textbf{U V }32[2]$, entre les deux équations
seulement un des éléments du tableau est défini.
On représente donc ça par un contexte qui à $v$ associe $\texttt{InR} (\textbf{V} ,\; [\texttt{Some}\; 1, \texttt{None}],\; [1])$.

À partir de cela on défini la sémantique d'une équation par une fonction qui prend en entrée un contexte
et qui en renvoie une version modifié si la sémantique ne produit aucune erreur.
Pour modifier le contexte, cette fonction évalue l'expression puis utilise la valeur obtenue ainsi que la liste de variables
pour mettre à jour le contexte.
La sémantique d'une liste d'équations est quant à elle définie par itération de la sémantique d'une équation.

Cette sémantique est celle la plus proche de l'implémentation actuelle de \UsubaA{} car c'est
la seule des 4 qui accepte de définir une même variable plusieurs fois.
L'idée étant, qu'une équation sans modification $=$ rajoute des valeurs dans le contexte
(i.e. remplace des \texttt{None} par une valeur) alors
alors qu'une équation avec modification $:=$ modifie le contexte (i.e. remplace des \texttt{Some}
par d'autres valeurs).

Mais cela à pour conséquence que le comportement d'un nœud dépend de l'ordre des équations.
Certaines permutations de l'ordre préservent la sémantique, cependant toutes les permutations ne sont pas équivalentes.
Ceci est une conséquence immédiate de l'existence d'équations avec modification.
Les autres sémantiques ont été définies pour ne pas dépendre de l'ordre des équations afin de plus ressembler à un modèle équationnel.
Cependant elles ne supportent pas la possibilité d'écrire des équations mutable.

Pour ce qui est d'utiliser cette sémantique dans des preuves de préservation de la sémantique, il est facile de définir une équivalence de programme.
Pour cela on peut énoncer que deux expressions sont équivalentes si, pour tous contextes, elles s'évaluent en les mêmes valeurs.
On obtient alors une relation d'équivalence congruente qui indique que si deux expressions sont équivalentes alors elles ont la même sémantique.
Et, de la même façon, on peut définir les équivalences d'équations, de déclarations et de nœuds.
De plus, cette sémantique possède l'avantage d'avoir un ordre d'évaluation clair ce qui permet de faire plus facilement
des preuves de préservation de la sémantique pour les différentes étapes de la compilation.


Désormais nous allons présenter les 3 autres sémantiques qui ont été définies dans le but de pouvoir interpréter des programmes sans dépendre de l'ordre
dans lequel les équations des nœuds sont écrites.
On considère donc désormais que toutes les équations sont des équations sans modification car les redéfinitions sont incompatibles avec une sémantique purement équationelle.

\subsection{Sémantique relationnelle}
\label{sec:relsem}

Cette sémantique est définie à partir de relations.
Par exemple, la sémantique d'une expression est définie par une relation entre une expression, un contexte et une valeur. 
Ceci permet de représenter de façon plus concise les erreurs car si l'évaluation d'une expression dans un certain contexte
génère une erreur,
alors, pour la dite expression, la relation n'associe aucune valeur au contexte.

La spécificité de cette sémantique se situe au niveau de la gestion du contexte. La sémantique d'une équation est
définie comme la vérification que la liste de variables et l'expression associés s'évaluent bien en des valeurs
compatibles pour le contexte fourni.
Le contexte quand à lui est définie au niveau de la sémantique globale d'un nœud.

\begin{align*}
  \forall \; names_{in} & \; values_{in} \; names_{out} \; values_{out}, \; \exists ! \; ctxt, \\
    & valid\_equations_{ctxt} \; eqns \rightarrow \\
    & names_{in} \mapsto_{ctxt} values_{in} \rightarrow \\
    & \text{map fst} \; ctxt = names_{in} \doubleplus names_{out} \doubleplus temps \rightarrow \\
    & names_{out} \mapsto_{ctxt} values_{out} \rightarrow \\
    & values_{in} \mapsto_{\textbf{node } f ( names_{in} ) \rightarrow ( names_{out} ) \; \textbf{vars}\; temps \; \textbf{let} \; eqns \; \textbf{tel}} values_{out}
\end{align*}

Cependant cette formule est relativement arbitraire car il en existe plusieurs variante qui sont intéressantes de considérer.
En effet l'unicité de l'existence du contexte n'est pas forcément une nécessité.
Par exemple, si on prend le système $\{y = 0 * x\}$ où $x$ est une variable temporaire et $y$ une variable renvoyée.
Alors la valeur de $y$ est indépendante de la valeur de $x$.
Il peut donc être décidé lors du choix de la sémantique que l'unicité de la valeur de $x$ est inutile et que seulement l'unicité de la valeur renvoyé est nécessaire.
Cependant stocker une preuve de l'unicité directement dans la sémantique nécessite que les différentes passes de réécriture de code dans le compilateur doivent
prouver la préservation de l'unicité. Ce qui peut être difficile dans le cas modification de l'ensemble des variables.
Pour résoudre ce problème, une autre possibilité est de ne pas demander la moindre unicité directement dans la sémantique, mais seulement avoir le typeur
qui prouve l'unicité et les différentes passes prouvent seulement la préservation de l'ensemble des résultats possibles.

En dehors du point abordé ci-dessus, cette sémantique possèdes plusieurs autres choses qu'il est important de remarquer :
\begin{itemize}
\item Elle est indépendante de l'ordre des équations (cela découle de la commutativité et l'associativité du “et” logique).
\item Elle ne garantie pas l'unicité des définitions contrairement aux précédentes, seulement la cohérence de
ces définitions pour un contexte donné. Par exemple le système $\{y = x; y = x\}$ est parfaitement valide pour cette sémantique.
De plus le système $\{x = 0 \times x\}$ l'est aussi.
\item Elle ne calcule pas.
\end{itemize}

Le troisième point est le plus problématique.
En effet cette sémantique ne calcule pas de contexte valide.
Cependant toute preuve qu'un programme est valide doit contenir tous les contextes de tous les nœuds.
Donc si un typeur veut garantir formellement que l'évaluatation d'un nœud ne plante pas, il
faut une preuve de correction qui calcule un contexte valide.
Ceci complique donc l'utilisation de cette sémantique dans un compilateur certifié.
Il faudrait donc définir une autre sémantique en plus de celle ci pour pouvoir prouver la correction d'un typeur.
Malgré ce défaut, l'aspect relationnelle de cette sémantique rend probablement plus facile les preuves de correction des autres passes d'un compilateur.

\subsection{Sémantique par tri topologique}
\label{sec:toposem}

La sémantique par tri topologique est de loin la plus compliquées des 4 sémantiques présentées ici car elle fait appel a de nombreuses notions et preuves
afin de pouvoir être définie.

Cette sémantique est une sémantique en appel par nom. En effet, plutôt que tout calculer jusqu'au résultat, l'évaluation regarde quelles variables doivent
être connues puis remonte dans les calculs afin de pouvoir obtenir le résultat.
Par exemple, si nous avons un nœud qui retourne \texttt{x}, on va donc chercher dans quel équation est définie \texttt{x}.
Puis l'on évalue l'expression associé afin d'obtenir la valeur de \texttt{x}, mais cela nécessite potentiellement de connaître la valeur de \texttt{y}.
On continue donc récursivement en calculant la valeur de \texttt{y} et ainsi de suite.

Cependant une telle évaluation n'est pas garantie de terminer. En effet, l'évaluation de $x$ dans le système $\{x = y; y = x\}$ ne termine pas.
Or, toute fonction définie dans la logique de Coq doit posséder une preuve de terminaison.
Cette nécessité est un pré-requis pour la cohérence car s'il est possible de définir une fonction divergente alors il est possible d'exhiber une preuve de faux.

Cependant, convaincre Coq que des fonctions mutuellement récursives terminent toujours est ardu à moins d'avoir un argument strictement décroissant.
Pour cela la méthode la plus courante pour prouver la terminaison est de rajouter un nouvel argument strictement décroissant.

Parmi les différentes possibilités d'arguments à rajouter, le plus courant est de rajouter un entier (que l'on nomme couramment “carburant”) qui décroît strictement
à chaque appel récursif. Cependant cette technique possède plusieurs limitation :
\begin{itemize}
\item Cela modifie le code extrait.
\item Il est difficile de garantir que l'on a mis suffisamment de carburant pour n'en manquer que dans les boucles infinies.
\end{itemize}

De plus dans le cas d'un compilateur, quand on réécrit un morceau de code, on risque de changer la quantité de carburant nécessaire pour évaluer une expression.
Il faut donc réussir à garantir que cette modification est aussi accompagné d'une modification du carburant fourni afin de s'assurer que l'on ne change
pas un code qui est interprété comme divergeant en un autre qui ne diverge pas ou inversement.

Pour éviter ces soucis il existe une autre possibilité : fournir un prédicat d'accessibilité. Il s'agit d'un terme dont le type
dépend des arguments de notre fonction dont on veux prouver la terminaison et dont les sous-termes correspondent aux appels récursifs de la fonction.
Cela permet d'éviter de ne jamais manquer de carburant si la famille inductive qui sert de prédicat d'accessibilité est bien définie.
Utiliser un prédicat possède l'énorme intérêt que si la famille inductive utilisée pour définir le prédicat d'accessibilité est une proposition,
alors le code extrait ne contient pas ce prédicat d'accessibilité. On obtient donc un code OCaml plus efficace.
Cependant cette technique possède aussi ses limites car il faut être capable de prouver l'existence d'un prédicat d'accessibilité.
Or, pour prouver l'existence d'un tel précidat il faut que notre fonction termine bien sur les arguments fournis.
Afin de résoudre ce problème, l'évaluation d'un nœud commence par vérifier si l'évaluation va terminer ou non.
Puis, si le vérificateur de terminaison l'accepte, le système de déclarations est utilisé pour évaluer les valeurs de renvoie.

Afin de pouvoir tester si l'évaluation va terminer ou non, on commence par réécrire notre système de déclarations en une liste d'équations.
Puis, un tri topologique est effectué sur ces équations pour obtenir la garantie qu'il n'existe pas de cycles.
Ce tri est effectué sur le graphe orienté obtenu en regardant si une équation dépend du calcul d'une autre.
En effet, si on prend deux équations tel que la première définie une variable \texttt{x} qui est utilisé par la seconde,
la seconde équation dépend de la première.
En raison de l'existence des tableaux en \Usuba{} et la possibilité de les définir
en plusieurs fois, les dépendances sont complexes et expliquées plus en détail dans la section \ref{sec:topo}.

Cette sémantique possède deux grosses limitations : 
\begin{itemize}
\item La sémantique est particulièrement lourde à définir car afin de prouver l'existence d'un prédicat d'accessibilité il faut être capable de calculer
le graphe (et prouver des propriétés dessus) puis prouver que si on a un tri topologique alors on a un prédicat d'accessibilité ce qui a nécessité plus
de 5k lignes de Coq.
\item De plus, toute modification sur le programme oblige de pouvoir
garantir que la vérificateur de terminaison continue à accepter la programme fourni.
Si il s'agit d'un prérequis pour la sémantique.
\end{itemize}

Le second problèmes rend donc cette sémantique difficilement utilisable pour prouver la correction d'un compilateur.
Cependant les outils implémentés lors de son implémentation peuvent tout de même être très utile pour un compilateur.
Plus particulièrement, le vérificateur de terminaison est probablement une étape nécessaire dans un typeur pour une sémantique
où l'évaluation ne dépend pas de l'ordre des équations.
Car pour pouvoir garantir que l'évaluation ne génère pas d'erreur il faut garantir qu'il n'est pas possible d'avoir une erreur de divergence.

\subsection{Sémantique par point fixe}
\label{sec:fixesem}

Cette dernière sémantique est sensée être plus légère que la précédente tout en étant encore une sémantique qui calcule
indépendamment de l'ordre des équations.

L'idée derrière celle-ci est que chaque équation est évaluée exactement une fois mais l'on ne connait pas encore l'ordre dans lequel il faut le faire.
Pour cela, la fonction d'évaluation parcourt la liste des équations en essayant de les évaluer. Pour chaque équation on a deux possibilités :
\begin{enumerate}
\item Soit on réussi à évaluer l'expression de cette équation, on modifie alors le contexte et on peut oublier l'équation.
\item Soit on ne réussi pas à évaluer l'expression, on garde donc l'équation pour plus tard.
\end{enumerate}

Une fois que l'on a parcouru toutes les équations plusieurs cas de figure peuvent avoir lieux :
\begin{enumerate}
\item Il reste plus aucune équation : on a donc fini et on peut renvoyer le contexte calculé.
\item Le nombre d'équations a strictement diminué mais il en reste : on refait une itération avec le contexte obtenue et les équations qui restent.
\item On a gardé le même nombre non nul d'équations : on renvoie une erreur car on n'arrive pas à conclure.
\end{enumerate}

Le nombre d'équations diminuant strictement à chaque appel récursif de cette évaluation termine après un nombre d'itération d'au plus la quantité initiale d'équations.
Mais on remarque que dans le cas où l'on restreint le nombre d'itération à uniquement 1, alors on retombe sur la sémantique par évaluation de la section
\ref{sec:evalsem} où l'on a interdit les équations de modification.

De plus, on est convaincu que cette sémantique est un sous ensemble stricte de la sémantique relationnelle de la section \ref{sec:relsem}.
L'inclusion est sensé être vrai mais cela n'a pas été vérifié dans Coq.
Cepdant, il existe des exemples simple de codes accepté par seulement la sémantique relationnelle.
Par exemple, le système $\{y = x; y = y\}$ (où $x$ est fourni en entrée) n'est pas valide pour notre nouvelle sémantique mais l'est pour la sémantique relationnelle.
Ceci vient du fait que la sémantique relationnelle accepte les duplicata de définition.
De plus la nouvelle sémantique calcule un plus petit point fixe mais l'existence d'un plus petit point fixe sans duplicata de définition
ne garanti pas l'absence d'erreur.
Par exemple, le système $\{y = 0 \times y\}$ est accepté seulement par la sémantique relationnelle.

Même si cette sémantique, tout comme la sémantique par tri topologique, garanti que toute valeur est défini au plus une fois
elle ne garanti pas que toutes les variables intermédiaires sont bien définies.
Contrairement à la sémantique par tri topologique où le vérificateur de terminaison s'assure que tous les tableaux ne sont jamais partiellement défini
même si la définition est réparti dans plusieurs équations différentes.
Cependant ceci est surtout un détail d'implémentation pour les deux sémantiques et cette différence peut être modifiée.

\section{Tri topologique sur les équations}
\label{sec:topo}

Nous allons désormais revenir sur la définition du tri topologique sur les équations calculées dans la sémantique par tri topologique section \ref{sec:toposem}.
Ce tri est important car il fait aussi parti des étapes nécessaire à l'implémentation d'un typeur qui vérifierait que le système d'équations est bien fondé.
Car tout compilateur aura besoin de produire un code ordonné en sortie et donc de pouvoir ordonner les calculs.

Afin de pouvoir effectuer un tri topologique sur les équations il faut d'abord avoir un graphe de dépendances entre les équations.
Pour cela nous allons poser la relation $x \prec y$ qui signifie que l'équation numéro $x$ dépend de l'équation numéro $y$.
Une telle dépendance arrive si l'équation numéro $y$ utilise une valeur définie dans l'équation numéro $x$.

Comme notre langage possède des tableaux, une variable est composé de deux informations : un identifiant et une liste d'indices.
Or pour pouvoir effectuer un tri sur le système $\{v[0] = 1; v[1] = v[0]\}$ où l'on a $v$ de type $\textbf{U V}\; 1[2]$ il faut avoir
une notion plus précise que seulement : “l'équation $v[1] = v[0]$ utilise et défini $v$”.

Maintenant si l'on regarde l'exemple ci dessous avec $v$ de type $\textbf{U V}\; 1[5]$ :
on remarque que l'équation 3 nécessite les deux autres équations.

\begin{align*}
  \{ v[0,1] & = (0, 1) ;\\
     v[3] &= 3 ;\\
     v[2,4] & = v[1,3] \}
\end{align*}

Pour parler de cela on définit la notion de chemin dans un identifiant comme une liste d'entiers.
De plus, on dit que le chemin est une instanciation d'une liste d'indiçages si chaque entiers est une instanciation de l'indiçage correspondant
et que les deux listes ont la même longueur.
\begin{itemize}
\item Pour un indice seul, l'entier associé est son unique instanciation.
\item Pour une liste d'entiers, les entiers de la liste sont ses instanciations.
\item Pour un intervalle, les entiers dedans sont ses instanciations.
\end{itemize}

On utilise cette notion de chemin pour obtenir la condition suivante :
si l'équation numéro $y$ utilise le chemin $c$ dans un identifiant $v$ et que l'équation numéro $x$ définit
le chemin $c$ de $v$ alors on a $x \prec y$.

Cependant cette propriété n'est pas encore suffisante.
En effet si une définition définit $v$ et qu'un autre utilise $v[0]$ alors la second dépend de la première.

On pose donc la définition suivante de $x \prec y$ : il existe deux chemins $c_{x}$ et $c_{y}$ et un identifiant $v$ tel que
\begin{enumerate}
\item l'équation numéro $x$ définie le chemin $c_{x}$ de l'identifiant $v$,
\item l'équation numéro $y$ utilise le chemin $c_{y}$ de l'identifiant $v$
\item et $c_{x}$ est un préfixe de $c_{y}$ ou $c_{y}$ est un préfixe de $c_{x}$
\end{enumerate}

À partir de cette relation d'ordre il est donc possible de calculer un tri topologique entre les équations.
S'il existe un cycle alors les définitions sont mutuellement dépendantes ce qui ne devrait pas avoir lieu.
L'absence de cycle garanti que toute évaluation des équations peut terminer ce qui permet à la sémantique par tri topologique
d'exhiber un prédicat d'accessibilité.

\section{Extensions possibles}

Étant donné que la sémantique de \UsubaA{} est non compositionnelle des modifications doivent
être apporté au langage. Certaines de ces modifications ont déjà été présenté précédemment et
d'autres extensions de \UsubaA{} sont possibles et ont été partiellement étudiées.
Dans les paragraphes suivants nous présenterons donc de telles extensions et leur intérêt.

\subsection{Autoriser l'indiçage sur les expressions}

À l'heure actuelle dans \UsubaA{} il est uniquement possible de faire des indiçages sur des variables et pas sur des expressions.
Ceci est une conséquence direct de l'absence de système de type ne qui permet pas de savoir comment les structures de tableaux
se propagent lors de différentes opérations.
Cependant le nouveau système de type présenté dans la section \ref{sec:typ} permet de résoudre ce problème.
De plus autoriser une telle syntaxe d'indiçage sur une expression pourrait permettre de faire de la substitution sur les termes
en rendant la syntaxe compositionnelle.

Malgré l'intérêt présenté ci dessus, une telle modification rendrais la sémantique non compositionnelle.
En effet, $v[1]$ n'aurais pas le même comportement suivant si l'indiçage a lieu dans une variable ou sur l'expression $v$.
La différence est que, si on indice sur l'expression $v$ alors il faut que tout $v$ soit défini et pas seulement la partie utilisée.

Il serait possible de définir une sémantique compositionnelle pour pouvoir avoir le même comportement pour les deux interprétations
de la syntaxe en autorisant de manipuler des valeurs non définies.
Cependant si on autorise les opérations à manipuler des valeurs potentiellement non définies alors le compilateur risque de générer
des codes qui génèrent des erreurs à l'exécution.
Par exemple, si l'on peut écrire $\{y[1] = (x / y)[0]\}$ et
si ce calcul n'est pas simplifié au cours de la compilation le code généré calculera $x[1] / y[1]$ avec $y[1]$ non défini.
Or si $y[1]$ est nul, le code assembleur associé générera une erreur de division par zéro.

\subsection{Élaboration de types}

Les règles de typages présentées dans la section \ref{sec:typ} font que de nombreux codes écrit en \UsubaA{} ne typent plus.
Ceci est une conséquence du fait que de nombreuses coercions implicites ne sont plus valides.
Une alternative pour pouvoir récupérer toutes les opérations qui ne sont désormais plus expressibles est de
rajouter une étape d'élaboration de type dans le compilateur afin de pouvoir continuer à interpréter tous ces codes.
Ceci permettrait de rajouter des coercions explicites dans le code afin d'avoir selon l'utilisateur des coercions implicites
alors que la sémantique n'accepte que des coercions explicites.

Il y a deux opérations qui ne sont plus possible à cause des règles de typages proposées parmi les 28 exemples valides de code écrits en \UsubaA{}.
Ces opérations sont les coercions au niveau des équations et les opérations binaires entre deux types différents.

Pour ce qui est des coercions implicites pour les équations, ce problème se résout facilement en remplaçant toutes les occurrences de
$v = e$ en $v = e \;\textbf{into}\;(\textbf{typeof}\; v)$.

Pour ce qui est des opérations binaires,
on ne peux pas calculer $x + y$ où $x$ est de type $\textbf{U V}\; 32[2][3]$ et $y$ de type $\textbf{U V}\; 32[6]$ d'après le système de types.
L'idée serait d'utiliser l'élaboration de type pour calculer un type $\tau_1 \land \tau_2$ à partir des types $\tau_1$ et $\tau_2$ de $x$ et $y$.
Mais seulement dans les cas où $\tau_1$ et $\tau_2$ sont des tableaux avec le même nombre d'éléments et que les éléments sont du même type.
Puis de transformer le code en $(x \; \textbf{into}\; \tau_1 \land \tau_2) + (y \; \textbf{into}\; \tau_1 \land \tau_2)$.

Du point de vue de l'utilisateur, cela donnerait l'impression qu'il y aurait une nouvelle règle \textsc{Binop} (figure \ref{fig:typ-binop}), alors qu'en réalité on utilise juste une coercion.

\begin{figure}[h]
  \begin{ottdefnblock}[]{$\Gamma  \ottsym{,}  \ottnt{P}  \ottsym{,}  \ottnt{A}  \vdash_E  \ottnt{e}  \ottsym{:}  \mathcal{T}$}{}
  \ottusedrule{\ottdruleBinopBis{}}
  \end{ottdefnblock}
  \caption{Nouvelle règle de typage des opérateurs binaires}
  \label{fig:typ-binop}
\end{figure}

Cependant il existe plusieurs définitions possibles pour ce PGCD sur deux types de tableaux :
\begin{enumerate}
\item Si les deux types sont compatibles, renvoyer le premier
\item Si les deux types sont identiques en renvoyer un sinon renvoyer le type du tableau unidimensionnel associé $type_{elements}[nb_{elements}]$
\item Renvoyer le type du tableau unidimensionnel associé dans tous les cas
\item Préserver toutes les dimensions extérieures identiques et aplatir à partir de la première dimension différente
\item Préserver toutes les dimensions intérieures identiques et aplatir à partir de la première dimension différente
\item Préserver autant de dimensions intérieures et extérieures que possible et aplatir le milieu
\end{enumerate}

À part la troisième règle qui semble particulièrement arbitraire il est difficile de choisir parmi les autres si l'une est
plus intéressantes les autres.
Or, les deux occurrences d'une telle opération dans les codes existant se font entre un tableau unidimensionnel et un tableau dimensionnel.
Les règles 2, 4, 5 et 6 sont donc indistinguables sur ces exemples ce qui rend toute comparaison difficile.

\subsection{Boucles temporelles}
\label{sec:wrap}

Un des objectifs de ce travail est d'essayer de rendre les codes écrit en \Usuba{} plus esthétiques.
Cela passe notamment par retirer les boucles qui induisent un style impératives et les remplacer par des structures plus équationelles.
En l'occurrence, la plupart des boucles dans les codes \UsubaA{} sont des \textit{map} et des \textit{fold} écrit à l'aide d'une boucle.
Pour ce qui est des \textit{map}, nous avons déjà présenté une syntaxe et un typage qui permet d'effectuer une telle opération avec un simple appel de nœud annoté.

Pour ce qui est des \textit{fold}, l'idée est de s'inspirer de Lustre \cite{lustre}
et rajouter deux constructions \texttt{fby} et \texttt{wrap} dans le langage.
L'idée étant qu'un \texttt{wrap} est une boucle mais avec une notion de temporalité et l'opération \texttt{fby} permet de calculer la valeur d'une expression
à l'instant précédent.
Afin d'expliquer mieux comment fonctionnent ces constructions nous allons nous baser sur une réécriture du nœud \texttt{Rectangle} de l'exemple \ref{lst:rectangle}
mais avec ces constructions (exemple \ref{lst:rec-wrap}).

\begin{lstlisting}[caption=Rectangle appliqué à une liste, label=lst:rec-wrap]
node Rectangle (plain:u16[4],key:const u16[26][4]) returns (cipher:u16[4])
vars
    tmp : u16[26][4]
let

  chipher = wrap i in [0, 24] vars tmp:u16[4] return tmp ^ key[25]
    let
      tmp = ShiftRows( SubColumn( (plain fby tmp) ^ key[i] ) )
    tel
tel
\end{lstlisting}

L'idée du \texttt{wrap} est d'exécuter l'ensemble des équations qui lui sont fournis à chaque instant afin de calculer un nouveau contexte.
Puis renvoie la valeur de l'expression fourni au dernier instant (ici à l'instant 24).
La construction \texttt{fby} permet elle d'interagir avec le temps. À la première itération (ici, l'instant 0) la valeur renvoyé et celle de l'expression à gauche.
Puis lors des instants suivant, la valeur renvoyées est celle de l'expression de droite calculé dans le contexte de l'instant précédant.

Cela permet donc d'implémenter facilement des \textit{fold} et ainsi de pouvoir remplacer dans les codes \Usuba{} la plupart des boucles qui resteraient après avoir
utilisé la syntaxe pour écrire des \textit{map}.

\subsection{Conditions et arguments statiques}

Une autre amélioration de \UsubaA{} serait de pouvoir rajouter des conditionnelles et la possibilité de faire des fonctions récursives.
Cela peut sembler contradictoire avec les propos tenus lors de l'introduction mais il existe un moyen de rajouter des conditions dans \Usuba{}.
En effet, il n'est pas possible de faire des conditions qui dépendent des valeurs pour des raisons de sécurité.
Cependant il est possible de rajouter des conditionnelles qui dépendent de paramètres statiques connu à la compilation.
De plus afin de pouvoir utiliser pleinement cette fonctionnalité en \Usuba{} il faudrait pouvoir fournir à l'appel de nœud un argument statique connu à la
compilation.

Il serait donc possible avec de tels fonctionnalités d'écrire une fonction récursive qui calcule un terme de la suite de Fibonacci
par expansion statique du circuit.

\begin{lstlisting}[caption=Fibonacci, label=lst:fibo]
node Fibo<i>() returns (val:u64)
let
  val = if i > 2
        then Fibo<i-1>() + Fibo<i-2>()
        else 1
tel
\end{lstlisting}

\section{Conclusion}

Dans ce rapport nous avons vu que \UsubaA{} est à l'heure actuelle un langage incomplet dont il manque une spécification de sa sémantique et
que celle qui peut peut être inféré à partir de l'implémentation du compilateur est non compositionnelle.
Cependant nous avons aussi vu différentes méthodes afin d'implémenter en Coq une spécification d'une sémantique pour \Usuba{} ainsi que plusieurs
constructions qui ont pour but d'améliorer la propreté des codes \UsubaA{} ainsi que de clarifier la sémantique en retirant des ambiguïtés.
De plus un système de types a aussi été proposé afin de pouvoir dans le futur intégrer un typeur à \textit{usubac} afin d'aider les utilisateurs à avoir des
messages d'erreur plus clair et prévisibles.

\section{Annexe}

Le code Coq pour spécifier les différentes sémantiques de la section \ref{sec:sem} est disponible sur le répositoire : \url{https://github.com/samsa1/usuba\_coq}.

Ce répositoire contient notamment :
\begin{itemize}
\item Un spécification en Coq de l'AST d'\UsubaB{} : \href{https://github.com/samsa1/usuba\_coq/blob/main/src/usuba\_AST.v}{src/usuba\_AST.v}
\item La sémantique par évaluation : \href{https://github.com/samsa1/usuba\_coq/blob/main/src/usuba\_sem.v}{src/usuba\_sem.v}
\item La sémantique relationnelle : \href{https://github.com/samsa1/usuba\_coq/blob/main/src/relation\_semantic.v}{src/relation\_semantic.v}
\item La sémantique par tri topologique : \href{https://github.com/samsa1/usuba\_coq/blob/main/src/topo\_sort/topo\_sem.v}{src/topo\_sort/topo\_sem.v}
\item La sémantique par point fixe : \href{https://github.com/samsa1/usuba\_coq/blob/main/src/subst\_semantic.v}{src/subst\_semantic.v}
\item Des preuves de correction d'optimisations : \href{https://github.com/samsa1/usuba\_coq/tree/main/src/normalization}{src/normalization}
\item Deux exemples de primitives : \href{https://github.com/samsa1/usuba\_coq/blob/main/src/examples/ace_bitslice.v}{src/examples/ace\_bitslice.v}
et \href{https://github.com/samsa1/usuba\_coq/blob/main/src/examples/aes.v}{src/examples/aes.v}
\item L'extracteur (\href{https://github.com/samsa1/usuba\_coq/blob/main/src/extract.v}{src/extract.v}) et le script de test (\href{https://github.com/samsa1/usuba_coq/blob/main/test.sh}{test.sh})
\end{itemize}

\printbibliography

\end{document}